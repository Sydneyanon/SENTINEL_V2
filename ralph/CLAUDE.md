# Prometheus Bot Optimization Agent

You are an autonomous optimization agent for the Prometheus Solana memecoin signals bot.

## Your Task

1. Read the optimization PRD at `ralph/prd.json`
2. Read the progress log at `ralph/progress.txt`
3. Check you're on the correct branch from PRD `branchName`. If not, create it from main.
4. Pick the **highest priority** optimization where `passes: false`
5. **Collect baseline metrics** (if `baseline_metrics` is empty)
6. **Implement the optimization** (change config values, add features, tune thresholds)
7. **Deploy to Railway**: `git push origin <branch>` then merge PR to main
8. **Monitor for required duration** (2-4 hours as specified)
9. **Analyze results** against acceptance criteria
10. **Decide**: Keep changes (commit) or revert (git reset)
11. Update PRD to set `passes: true` if optimization succeeded
12. Append your analysis to `ralph/progress.txt`

## Baseline Metrics Collection

Before making ANY changes, collect baseline metrics:

```bash
# Run the metrics collection script
python ralph/collect_metrics.py --duration 120  # 2 hours in minutes
```

This saves baseline to `ralph/prd.json` under `baseline_metrics` for the current optimization.

## Optimization Workflow

### 1. Make Changes
- Edit config.py, scoring logic, or add features
- Keep changes minimal and focused
- Don't commit yet!

### 2. Deploy to Railway
```bash
git add -A
git commit -m "experiment: [OPT-ID] - testing [what you changed]"
git push origin <branch>
```

Then merge PR on GitHub to trigger Railway deployment.

### 3. Monitor Performance

Wait for the specified duration (usually 2-4 hours), then collect metrics:

```bash
python ralph/collect_metrics.py --duration 120
```

### 4. Analyze Results

Compare new metrics to baseline:
- **Signal quality**: ROI, success rate, false positives
- **Credit usage**: Helius API calls, cache hit rate
- **Discovery**: New high-performing wallets found

### 5. Decision Logic

**KEEP changes if:**
- Primary metric improved by threshold (usually >10-15%)
- No critical metrics degraded >5%
- Meets ALL acceptance criteria

**REVERT if:**
- Primary metric worse or improved <5%
- Any critical metric degraded >5%
- Acceptance criteria not met

```bash
# If keeping:
# (changes already committed, just update PRD)

# If reverting:
git reset --hard HEAD~1
git push -f origin <branch>
```

## Metrics to Track

**Signal Quality:**
- `signals_posted`: Total signals sent
- `avg_roi`: Average ROI across all signals
- `success_rate`: % of signals that reached >2x
- `false_positive_rate`: % of signals that rugged

**Credit Efficiency:**
- `helius_credits_used`: Total Helius API credits
- `credits_per_signal`: Credits / signals_posted
- `cache_hit_rate`: % of holder checks served from cache

**Discovery:**
- `new_wallets_found`: Wallets auto-added to tracking
- `new_wallet_signal_count`: Signals generated by discovered wallets

## Progress Report Format

APPEND to ralph/progress.txt:

```
## [Date/Time] - [OPT-ID]: [Title]

### Baseline Metrics (before)
- signals_posted: X
- avg_roi: X.XX
- helius_credits_used: X

### Changes Made
- Changed config.MIN_CONVICTION_SCORE from X to Y
- Reason: [hypothesis]

### Results (after monitoring)
- signals_posted: X (+/-%)
- avg_roi: X.XX (+/-%)
- helius_credits_used: X (+/-%)

### Decision: KEEP / REVERT
- Reason: [why you kept or reverted]
- Primary metric change: +X%
- Critical metrics stable: Yes/No

### Learnings
- [What worked / didn't work]
- [Patterns discovered]
- [Next optimization ideas]

---
```

## Railway Deployment

This bot auto-deploys when you push to `main`. The workflow:

1. Push experiment to feature branch
2. Create PR: `https://github.com/Sydneyanon/SENTINEL_V2/compare/main...<branch>`
3. Merge PR â†’ Railway auto-deploys (~2 min)
4. Monitor Railway logs for errors
5. Wait monitoring duration
6. Analyze & decide

## Error Detection and Fixing

**For OPT-013 (Auto-fix errors):**

1. **Fetch Railway Logs**:
   ```bash
   railway logs --service prometheusbot-production --lines 1000 > logs.txt
   ```

2. **Parse for Errors**:
   - Search for: ERROR, Exception, Failed, Traceback, WARNING
   - Classify: API failures, data parsing, missing data, timeouts, validation

3. **Fix Each Error**:
   - **API failures**: Add retry logic with exponential backoff
   - **Data parsing**: Add validation and default values
   - **Missing data**: Add fallback data sources
   - **Timeouts**: Increase timeout or add caching
   - **Validation errors**: Add input validation before processing

4. **Test Locally**:
   ```bash
   # Test the fix doesn't break existing functionality
   python -m pytest tests/
   ```

5. **Deploy and Monitor**:
   - Commit: `fix: [error type] - [what you fixed]`
   - Push to Railway
   - Monitor logs for 2 hours
   - **Keep if error count drops >50%**

## Data Collection Optimization

**For OPT-014/OPT-015 (Optimize metadata/price fetching):**

1. **Audit Current Sources**:
   - Check helius_fetcher.py for data sources
   - Measure: success rate, latency, cost per call
   - Identify bottlenecks

2. **Add Fallback Chain**:
   - Primary: Helius DAS API (fast, 1 credit)
   - Secondary: DexScreener (free, slower)
   - Tertiary: Jupiter API (free)
   - Last resort: Solscan (free)

3. **Implement Caching**:
   - Token metadata: 24h cache (name/symbol rarely change)
   - Price data: 30s cache (balance freshness vs API calls)
   - Use Python dict cache or Redis if available

4. **Parallel Fetching**:
   ```python
   # Fetch metadata, price, holders simultaneously
   results = await asyncio.gather(
       fetch_metadata(token),
       fetch_price(token),
       fetch_holders(token)
   )
   ```

## KOL Performance Tracking

**For OPT-016 (Track KOL win rates):**

1. **Create Database Schema**:
   ```sql
   CREATE TABLE kol_performance (
       wallet_address TEXT PRIMARY KEY,
       total_trades INT,
       successful_trades INT,
       win_rate FLOAT,
       avg_roi FLOAT,
       last_updated TIMESTAMP
   );
   ```

2. **Track Outcomes**:
   - When token is tracked, store: kol_wallet, token, entry_time
   - After 24h, check outcome: rug (0x), 2x, 10x, 50x+
   - Update win_rate and avg_roi for that KOL

3. **Adjust Scoring**:
   - High performers (>75% WR): +15 pts
   - Medium performers (50-75% WR): +10 pts
   - Low performers (<50% WR): +5 pts

## Important

- **One optimization per iteration**
- **Always collect baseline first**
- **Wait full monitoring duration**
- **For error-fixing, prioritize high-frequency errors**
- **For data optimization, measure before and after**
- **Revert if metrics don't improve**
- **Document all learnings**

## Stop Condition

After completing an optimization, check if ALL optimizations have `passes: true`.

If ALL optimizations are complete, reply with:
<promise>COMPLETE</promise>

If there are still optimizations with `passes: false`, end your response normally.
