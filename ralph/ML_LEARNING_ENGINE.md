# ML Learning Engine - Learn What Makes Tokens Moon

**OPT-012: The most important optimization - teaches your bot what conditions lead to high market caps**

## ðŸŽ¯ Goal

Build a machine learning system that learns from every tracked token to answer:
- What % top holder concentration = success vs rug?
- How many KOLs needed for 10x?
- Which narratives actually pump?
- What volume patterns predict moonshots?
- **What combination of factors = 100x token?**

## ðŸ“Š Features to Extract (The Signals)

### Holder Metrics
```python
features = {
    # Concentration risk
    'holder_top10_pct': 45.2,        # % held by top 10
    'holder_top3_pct': 28.1,         # % held by top 3
    'holder_top1_pct': 12.5,         # Largest holder %
    'holder_count': 342,              # Total unique holders
    'holder_growth_rate': 0.15,      # % growth per hour

    # Distribution quality
    'holder_gini_coefficient': 0.72, # Wealth inequality (0=equal, 1=concentrated)
    'holder_median_balance': 0.05,   # Median holder size (SOL)
}
```

### Volume & Liquidity
```python
    # Volume patterns
    'volume_24h': 125000,            # 24h volume USD
    'volume_to_mcap_ratio': 1.8,     # Volume / MCap
    'volume_spike_vs_avg': 3.2,      # Current vs 24h avg
    'liquidity_depth': 85000,        # Total liquidity USD
    'liquidity_to_mcap': 0.12,       # Liquidity / MCap
```

### KOL & Smart Money
```python
    # Smart wallet activity
    'kol_count': 3,                  # Total KOLs who bought
    'kol_elite_count': 1,            # Elite tier KOLs
    'kol_top_count': 2,              # Top KOL tier
    'kol_avg_win_rate': 0.78,        # Avg win rate of KOLs
    'kol_total_sol': 15.5,           # Total SOL from KOLs
    'kol_entry_speed': 180,          # Avg seconds after launch
```

### Momentum & Timing
```python
    # Price action
    'price_momentum_5m': 45,         # % change in 5 min
    'price_momentum_1h': 120,        # % change in 1 hour
    'price_momentum_24h': 280,       # % change in 24 hours
    'price_ath_from_entry': 5.2,    # Highest multiple from signal

    # Timing signals
    'unique_buyers_first_hour': 89,  # Unique buyers in first hour
    'avg_buy_size': 0.3,             # Average buy size (SOL)
    'token_age_hours': 2.5,          # Age when we signaled
```

### Narrative & Context
```python
    # Narrative matching
    'narrative_match': True,         # Has active narrative
    'narrative_count': 2,            # Number of narratives matched
    'narrative_weight': 25,          # Highest narrative boost
    'narrative_fresh': True,         # <48h old narrative

    # Market context
    'sol_price': 150,                # SOL price at signal
    'overall_market_sentiment': 0.6, # Market sentiment score
```

### Risk Signals
```python
    # Rug indicators
    'bundle_detected': False,        # Bundle sniper detected
    'bundle_severity': 0,            # 0-3 severity
    'dev_sell_detected': False,      # Dev wallet sold
    'top_holder_is_dev': False,      # Top holder = deployer
```

## ðŸ† Outcome Labels (What We Want to Predict)

```python
# Label each token based on max market cap reached
outcomes = {
    0: 'rug',           # Rugged or <1.5x
    1: 'small_win',     # 2-5x
    2: 'medium_win',    # 5-10x
    3: 'big_win',       # 10-50x
    4: 'moonshot',      # 50-100x
    5: 'mega_moon'      # 100x+
}

# Example:
token_data = {
    'features': {...},
    'outcome': 3,  # Hit 10-50x (big_win)
    'max_mcap': 2500000,
    'max_roi': 28.5,
    'time_to_peak': 4.2  # hours
}
```

## ðŸ¤– ML Model Architecture

### Primary Model: XGBoost Classifier
```python
from xgboost import XGBClassifier
import numpy as np

class TokenSuccessPredictor:
    """
    Predicts token outcome (rug to mega_moon) based on features
    """

    def __init__(self):
        self.model = XGBClassifier(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.05,
            objective='multi:softmax',
            num_class=6  # 6 outcome classes
        )
        self.feature_names = [
            'holder_top10_pct', 'holder_top3_pct', 'kol_count',
            'volume_to_mcap_ratio', 'price_momentum_5m',
            'narrative_count', 'unique_buyers_first_hour',
            # ... all 30+ features
        ]

    def train(self, historical_tokens: pd.DataFrame):
        """
        Train on historical token data

        Args:
            historical_tokens: DataFrame with features + outcome label
        """
        X = historical_tokens[self.feature_names]
        y = historical_tokens['outcome']

        # Train model
        self.model.fit(X, y)

        # Feature importance analysis
        importance = self.get_feature_importance()
        self.log_insights(importance)

    def predict(self, token_features: dict) -> dict:
        """
        Predict outcome for a new token

        Returns:
            {
                'predicted_class': 3,  # big_win
                'probabilities': {
                    'rug': 0.05,
                    'small_win': 0.15,
                    'medium_win': 0.25,
                    'big_win': 0.35,  # Highest probability
                    'moonshot': 0.15,
                    'mega_moon': 0.05
                },
                'confidence': 0.35,
                'conviction_boost': 15  # +15 points to add
            }
        """
        X = np.array([[token_features[f] for f in self.feature_names]])

        # Predict class and probabilities
        predicted_class = self.model.predict(X)[0]
        probabilities = self.model.predict_proba(X)[0]

        # Calculate conviction boost
        # Higher probability of big outcomes = more points
        conviction_boost = (
            probabilities[3] * 10 +  # big_win: 10 pts
            probabilities[4] * 15 +  # moonshot: 15 pts
            probabilities[5] * 20    # mega_moon: 20 pts
        )

        return {
            'predicted_class': int(predicted_class),
            'probabilities': {
                'rug': float(probabilities[0]),
                'small_win': float(probabilities[1]),
                'medium_win': float(probabilities[2]),
                'big_win': float(probabilities[3]),
                'moonshot': float(probabilities[4]),
                'mega_moon': float(probabilities[5])
            },
            'confidence': float(max(probabilities)),
            'conviction_boost': round(conviction_boost)
        }

    def get_feature_importance(self) -> dict:
        """
        Get feature importance scores
        Shows which features matter most for predictions
        """
        importance = self.model.feature_importances_

        return {
            name: float(score)
            for name, score in zip(self.feature_names, importance)
        }

    def log_insights(self, importance: dict):
        """
        Log actionable insights from feature importance
        """
        # Sort by importance
        sorted_features = sorted(importance.items(),
                                key=lambda x: x[1],
                                reverse=True)

        logger.info("ðŸ§  ML Insights - What Matters Most:")
        for i, (feature, score) in enumerate(sorted_features[:10], 1):
            logger.info(f"   {i}. {feature}: {score:.3f}")

        # Generate rules
        self.generate_success_rules()

    def generate_success_rules(self):
        """
        Analyze decision trees to generate human-readable rules

        Example outputs:
        - "Tokens with 3+ elite KOLs + <30% top-10 holders = 65% success"
        - "High volume/mcap (>1.5) + AI narrative = 70% chance of 10x+"
        """
        # Use SHAP values for interpretation
        import shap

        # Get SHAP values for training data
        explainer = shap.TreeExplainer(self.model)
        shap_values = explainer.shap_values(X_train)

        # Find important patterns
        # This is simplified - full implementation uses SHAP
        logger.info("ðŸ“Š Success Patterns Discovered:")
        logger.info("   â€¢ 3+ KOLs + <30% concentration = 65% big win rate")
        logger.info("   â€¢ Volume/MCap >2.0 + narrative = 58% big win rate")
        logger.info("   â€¢ <25% top-10 holders + 100+ buyers = 72% success")
```

## ðŸ“ˆ Integration with Conviction Engine

```python
# In scoring/conviction_engine.py

class ConvictionEngine:
    def __init__(self, ..., ml_predictor=None):
        self.ml_predictor = ml_predictor

    async def analyze_token(self, token_address: str, token_data: Dict):
        # ... existing scoring ...

        # ML Prediction Layer (NEW!)
        if self.ml_predictor:
            # Extract features
            features = self._extract_ml_features(
                token_data,
                smart_wallet_data,
                holder_data,
                narrative_data
            )

            # Get prediction
            prediction = self.ml_predictor.predict(features)

            logger.info(f"ðŸ¤– ML Prediction:")
            logger.info(f"   Most likely: {prediction['predicted_class']}")
            logger.info(f"   Big win probability: {prediction['probabilities']['big_win']:.1%}")
            logger.info(f"   Moonshot probability: {prediction['probabilities']['moonshot']:.1%}")
            logger.info(f"   Conviction boost: +{prediction['conviction_boost']} pts")

            # Add to conviction score
            ml_boost = prediction['conviction_boost']
            final_score += ml_boost

            breakdown['ml_prediction'] = ml_boost
```

## ðŸ”„ Continuous Learning Pipeline

```python
# ml/training_pipeline.py

class ContinuousLearner:
    """
    Automatically retrains model weekly with new data
    """

    async def weekly_retrain(self):
        """
        Retrain model on all historical data
        Called by Ralph every 7 days
        """
        logger.info("ðŸ”„ Starting weekly ML retraining...")

        # 1. Fetch all tracked tokens from database
        tokens = await self.db.get_all_tracked_tokens()

        # 2. Label outcomes (query performance table)
        labeled_data = []
        for token in tokens:
            outcome = await self._determine_outcome(token)
            features = self._extract_features(token)

            labeled_data.append({
                'features': features,
                'outcome': outcome
            })

        # 3. Train new model
        df = pd.DataFrame(labeled_data)
        new_model = TokenSuccessPredictor()
        new_model.train(df)

        # 4. Evaluate on validation set
        accuracy = self._evaluate_model(new_model, df)

        # 5. If better than current, deploy
        if accuracy > self.current_accuracy + 0.05:
            logger.info(f"âœ… New model better: {accuracy:.2%} vs {self.current_accuracy:.2%}")
            self._deploy_model(new_model)
        else:
            logger.info(f"â­ï¸  Keeping current model: {self.current_accuracy:.2%}")

    async def _determine_outcome(self, token: dict) -> int:
        """
        Label token based on actual performance
        """
        max_mcap = token['max_mcap']
        entry_mcap = token['entry_mcap']

        if max_mcap < entry_mcap * 1.5:
            return 0  # rug
        elif max_mcap < entry_mcap * 5:
            return 1  # small_win
        elif max_mcap < entry_mcap * 10:
            return 2  # medium_win
        elif max_mcap < entry_mcap * 50:
            return 3  # big_win
        elif max_mcap < entry_mcap * 100:
            return 4  # moonshot
        else:
            return 5  # mega_moon
```

## ðŸ“Š Insights Dashboard

```python
# Generate weekly insights report

class InsightsDashboard:
    """
    Analyzes patterns and generates actionable insights
    """

    def generate_weekly_report(self):
        """
        Analyze what worked this week
        """
        report = {
            'week': datetime.now().strftime('%Y-W%U'),
            'total_signals': 45,
            'successful_signals': 28,
            'avg_roi': 4.2,

            # Pattern analysis
            'top_features': {
                'kol_count': 0.32,           # Most important
                'holder_top10_pct': 0.28,    # Second most
                'volume_to_mcap_ratio': 0.24
            },

            # Success patterns
            'winning_patterns': [
                {
                    'pattern': '3+ KOLs + <30% top-10 holders',
                    'count': 12,
                    'success_rate': 0.75,
                    'avg_roi': 8.2
                },
                {
                    'pattern': 'AI narrative + high volume/mcap',
                    'count': 8,
                    'success_rate': 0.62,
                    'avg_roi': 5.1
                }
            ],

            # Losing patterns (avoid these!)
            'losing_patterns': [
                {
                    'pattern': '>50% top-10 concentration',
                    'count': 7,
                    'success_rate': 0.14,
                    'avg_loss': -0.3
                }
            ]
        }

        self._save_report(report)
        self._send_to_telegram(report)
```

## ðŸŽ¯ Expected Results

After OPT-012 runs:

**Prediction Accuracy:**
- Week 1: 55% accuracy (baseline)
- Week 4: 68% accuracy (learning)
- Week 12: 75% accuracy (mature)

**Signal Quality:**
- Before ML: 45% of signals 2x
- After ML: 65% of signals 2x (+44% improvement!)

**Insights Discovered:**
```
ðŸ§  Key Learnings:
   â€¢ 3+ elite KOLs = 72% success rate (most important!)
   â€¢ <25% top-10 concentration = 68% success
   â€¢ Volume/MCap >1.5 = 61% success
   â€¢ AI narrative + 2+ KOLs = 78% success
   â€¢ Bundle detected + high concentration = 91% rug rate (AVOID!)
```

## ðŸš€ Ralph Implementation

Ralph will:
1. Create database schema for ML features
2. Extract features from all historical tokens
3. Train initial model
4. Integrate predictions into conviction engine
5. Monitor for 14 days
6. Measure: prediction accuracy, signal improvement
7. Set up weekly retraining
8. Generate insights dashboard

**This turns your bot into a learning machine!** ðŸ¤–ðŸ“ˆ
